# -*- coding: utf-8 -*-
"""ML NN 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SbRjzioC6Tvvi5nZxvKkdJRaxbdQQ5X_

**PCA Data Set**
"""

"""**PCA Dataset Deep Learning**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Load the dataset
data = pd.read_excel('/content/data_pca_v1.xlsx')

# Remove unnecessary columns
data = data.drop(columns=["CLIENT_ID"])

# Count occurrences of 1 and 0 in the target variable
target_counts = data["Attrition_Flag"].value_counts()

print("Number of occurrences of 1 (Positive class):", target_counts[1])
print("Number of occurrences of 0 (Negative class):", target_counts[0])

# Separate features and target variable
X = data.drop(columns=["Attrition_Flag"])
y = data["Attrition_Flag"]

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the neural network architecture
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(32, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Define early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)

# Predict probabilities
train_probs = model.predict(X_train_scaled).flatten()
test_probs = model.predict(X_test_scaled).flatten()

# Convert probabilities to binary predictions based on a threshold (e.g., 0.5)
train_preds = (train_probs > 0.5).astype(int)
test_preds = (test_probs > 0.5).astype(int)

# Evaluation metrics
train_accuracy = accuracy_score(y_train, train_preds)
test_accuracy = accuracy_score(y_test, test_preds)

train_precision = precision_score(y_train, train_preds)
test_precision = precision_score(y_test, test_preds)

train_recall = recall_score(y_train, train_preds)
test_recall = recall_score(y_test, test_preds)

train_f1_score = f1_score(y_train, train_preds)
test_f1_score = f1_score(y_test, test_preds)

train_roc_auc = roc_auc_score(y_train, train_probs)
test_roc_auc = roc_auc_score(y_test, test_probs)

# Print evaluation metrics
print("Train Accuracy:", train_accuracy)
print("Test Accuracy:", test_accuracy)
print("Train Precision:", train_precision)
print("Test Precision:", test_precision)
print("Train Recall:", train_recall)
print("Test Recall:", test_recall)
print("Train F1 Score:", train_f1_score)
print("Test F1 Score:", test_f1_score)
print("Train ROC-AUC Score:", train_roc_auc)
print("Test ROC-AUC Score:", test_roc_auc)